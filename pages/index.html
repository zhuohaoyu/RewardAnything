---
layout: default
title: "Home"
description: "RewardAnything: Generalizable Principle-Following Reward Models"
---

<!-- Hero Section -->
<section class="gradient-bg text-slate-700 py-12">
    <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 text-center">
        <div class="mb-6">
            <!-- Use your regular logo - it will look perfect on this lighter background -->
            <img src="{{ '/assets/images/rewardanything-logo-horizontal.png' | relative_url }}" 
                 alt="RewardAnything" 
                 class="h-14 md:h-18 w-auto mx-auto mb-4">
        </div>
        
        <p class="text-2xl md:text-3xl mb-10 text-slate-700 max-w-4xl mx-auto font-bold">
            Generalizable Principle-Following Reward Models
        </p>
        
        <!-- Simplified TLDR with cleaner formatting -->
        <div class="text-base md:text-lg mb-10 text-slate-600 max-w-7xl mx-auto leading-relaxed">
            <p class="mb-4">
                Traditional reward models learn <span class="font-semibold text-slate-800">implicit preferences</span> behind chosen-rejected pairs,<br>
                but human values are <span class="italic text-slate-700">far more nuanced</span> than any single distribution.
            </p>
            <p>
                <span class="font-semibold text-slate-800">Just as LLMs follow instructions</span>, reward models should follow<br>
                <span class="font-semibold text-blue-700">explicitly specified principles</span>‚Äîenabling inference-time adaptation to diverse evaluation criteria<br>
                <span class="font-medium text-slate-700">without costly retraining</span>.
            </p>
        </div>
        
        <!-- Updated CTA Buttons -->
        <div class="flex flex-col sm:flex-row gap-3 justify-center items-center mb-10">
            <a href="{{ site.paper_url | default: '#' }}" 
               class="inline-flex items-center bg-white text-slate-700 px-6 py-2.5 rounded-lg font-semibold hover:bg-slate-50 transition-all transform hover:scale-105 shadow-lg border border-slate-200">
                üìÑ <span class="ml-2">Paper</span>
            </a>
            <a href="{{ site.huggingface_url | default: '#' }}" 
               class="inline-flex items-center bg-gradient-to-r from-yellow-400 to-orange-500 text-white px-6 py-2.5 rounded-lg font-semibold hover:from-yellow-500 hover:to-orange-600 transition-all transform hover:scale-105 shadow-lg">
                ü§ó <span class="ml-2">Model Weights</span>
            </a>
            <a href="#quickstart" 
               class="inline-flex items-center bg-gradient-to-r from-emerald-500 to-teal-600 text-white px-6 py-2.5 rounded-lg font-semibold hover:from-emerald-600 hover:to-teal-700 transition-all transform hover:scale-105 shadow-lg">
                üíª <span class="ml-2">Get Started</span>
            </a>
        </div>
    </div>
</section>

<!-- Authors Section -->
<section class="py-10 bg-white">
    <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 text-center">
        <div class="text-base md:text-lg text-gray-700 mb-6">
            <div class="space-y-3">
                <!-- First line of authors (5 authors) -->
            <div class="flex flex-wrap justify-center gap-x-6 gap-y-2">
                <span>Zhuohao Yu<sup>1,¬ß</sup></span>
                <span>Jiali Zeng<sup>2</sup></span>
                <span>Weizheng Gu<sup>1</sup></span>
                <span>Yidong Wang<sup>1</sup></span>
                <span>Jindong Wang<sup>3</sup></span>
                </div>
                <!-- Second line of authors (5 authors) -->
                <div class="flex flex-wrap justify-center gap-x-6 gap-y-2">
                <span>Fandong Meng<sup>2</sup></span>
                <span>Jie Zhou<sup>2</sup></span>
                <span>Yue Zhang<sup>4</sup></span>
                <span>Shikun Zhang<sup>1</sup></span>
                <span>Wei Ye<sup>1,‚Ä†</sup></span>
            </div>
        </div>
        </div>
        <div class="text-base md:text-lg text-gray-600">
            <div class="mb-4 font-bold">
                <sup>1</sup>Peking University &emsp;
                <sup>2</sup>WeChat AI &emsp;
                <sup>3</sup>William & Mary &emsp;
                <sup>4</sup>Westlake University
            </div>
            <p class="text-sm md:text-base text-gray-500">
                <sup>¬ß</sup>Work done during internship at WeChat AI &emsp; <sup>‚Ä†</sup>Corresponding author
            </p>
        </div>
    </div>
</section>

<!-- Problem & Solution Overview -->
<section class="py-20 bg-gray-50">
    <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
        <div class="text-center mb-16">
            <h2 class="text-3xl md:text-4xl font-bold text-gray-900 mb-4">The Problem with Current Reward Models</h2>
            <p class="text-xl text-gray-600 max-w-4xl mx-auto">
                Traditional reward models learn implicit preferences from fixed datasets, making them rigid and unable to adapt to diverse real-world needs.
            </p>
        </div>

        <!-- Research Figure Container -->
        <div class="paper-figure-container mb-16">
            <div class="max-w-5xl mx-auto">
                <img src="{{ '/assets/images/figure_1_placeholder.jpg' | relative_url }}" 
                     alt="Figure 1: Current post-training optimization paradigm vs RewardAnything approach"
                     class="w-full h-auto rounded-lg shadow-sm">
                <p class="text-sm text-gray-600 text-center mt-4 italic">
                    <strong>Figure 1:</strong> Current post-training optimization requires costly retraining for different preferences. 
                    RewardAnything directly follows natural language principles without retraining.
                </p>
            </div>
        </div>

        <div class="grid grid-cols-1 lg:grid-cols-2 gap-12">
            <!-- Current Limitations -->
            <div class="bg-red-50 p-8 rounded-xl">
                <div class="text-red-600 text-2xl mb-4">‚ö†Ô∏è</div>
                <h3 class="text-xl font-bold text-red-900 mb-4">Current Limitations</h3>
                <ul class="space-y-3 text-red-800">
                    <li class="flex items-start">
                        <span class="text-red-600 mr-2">‚Ä¢</span>
                        <span><strong>Limited Adaptability:</strong> Need to retrain for different preference criteria</span>
                    </li>
                    <li class="flex items-start">
                        <span class="text-red-600 mr-2">‚Ä¢</span>
                        <span><strong>Implicit Learning:</strong> Learn biases from spurious correlations in data</span>
                    </li>
                    <li class="flex items-start">
                        <span class="text-red-600 mr-2">‚Ä¢</span>
                        <span><strong>Costly Updates:</strong> Require new preference data collection and retraining</span>
                    </li>
                    <li class="flex items-start">
                        <span class="text-red-600 mr-2">‚Ä¢</span>
                        <span><strong>Poor Interpretability:</strong> Difficult to understand decision rationale</span>
                    </li>
                </ul>
            </div>

            <!-- Our Solution -->
            <div class="bg-green-50 p-8 rounded-xl">
                <div class="text-green-600 text-2xl mb-4">‚úÖ</div>
                <h3 class="text-xl font-bold text-green-900 mb-4">RewardAnything Solution</h3>
                <ul class="space-y-3 text-green-800">
                    <li class="flex items-start">
                        <span class="text-green-600 mr-2">‚Ä¢</span>
                        <span><strong>Principle-Following:</strong> Adapt to any explicit natural language criteria</span>
                    </li>
                    <li class="flex items-start">
                        <span class="text-green-600 mr-2">‚Ä¢</span>
                        <span><strong>Zero Retraining:</strong> Dynamic adaptation without model updates</span>
                    </li>
                    <li class="flex items-start">
                        <span class="text-green-600 mr-2">‚Ä¢</span>
                        <span><strong>Transparent Reasoning:</strong> Explicit explanations for decisions</span>
                    </li>
                    <li class="flex items-start">
                        <span class="text-green-600 mr-2">‚Ä¢</span>
                        <span><strong>Bias Mitigation:</strong> Clear principles eliminate spurious correlations</span>
                    </li>
                </ul>
            </div>
        </div>
    </div>
</section>

<!-- Installation & Usage Guide -->
<section id="quickstart" class="py-20 bg-white">
    <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
        <div class="text-center mb-16">
            <h2 class="text-3xl md:text-4xl font-bold text-gray-900 mb-4">üöÄ Quick Start</h2>
            <p class="text-xl text-gray-600 max-w-4xl mx-auto">
                RewardAnything offers three flexible deployment options to fit your workflow, from quick experimentation to production-scale evaluation.
            </p>
        </div>

            <!-- Installation -->
        <div class="mb-16">
            <div class="bg-gray-50 rounded-xl p-8">
                <h3 class="text-xl font-bold text-gray-900 mb-4">üì¶ Installation</h3>
                <div class="bg-gray-900 rounded-lg p-4">
                    <code class="text-green-400 font-mono">pip install rewardanything</code>
                </div>
            </div>
        </div>

        <!-- Three Deployment Methods -->
        <div class="grid md:grid-cols-3 gap-8 mb-16">
            <!-- Method 1: Local Inference -->
            <div class="deployment-card blue bg-gradient-to-br from-blue-50 to-indigo-100 rounded-xl p-6 border border-blue-200" 
                 onclick="selectDeploymentMethod('local')" data-method="local">
                <div class="flex items-center mb-4">
                    <span class="text-2xl mr-3">üè†</span>
                    <h3 class="text-xl font-bold text-gray-900">Local Inference</h3>
                </div>
                <p class="text-gray-600 mb-4">Perfect for quick experimentation and research</p>
                
                <div class="mb-4">
                    <div class="text-sm font-semibold text-green-700 mb-2">‚úÖ Pros:</div>
                    <ul class="text-sm text-gray-600 space-y-1">
                        <li>‚Ä¢ Simple setup, no external dependencies</li>
                        <li>‚Ä¢ Full control over the model</li>
                        <li>‚Ä¢ Works offline once downloaded</li>
                    </ul>
                </div>
                
                <div class="mb-4">
                    <div class="text-sm font-semibold text-orange-700 mb-2">‚ö†Ô∏è Cons:</div>
                    <ul class="text-sm text-gray-600 space-y-1">
                        <li>‚Ä¢ Requires local GPU (8GB+ VRAM)</li>
                        <li>‚Ä¢ Slower for large batch processing</li>
                    </ul>
                </div>

                <div class="mb-4">
                    <div class="text-sm font-semibold text-blue-700 mb-2">üí° Best for:</div>
                    <ul class="text-sm text-gray-600 space-y-1">
                        <li>‚Ä¢ Quick testing and research</li>
                        <li>‚Ä¢ Small-scale evaluation</li>
                        <li>‚Ä¢ Offline environments</li>
                    </ul>
                </div>
                
                <div class="flex justify-center">
                    <div class="text-blue-600 text-sm font-medium bg-blue-100 px-3 py-2 rounded-lg hover:bg-blue-200 transition-colors">
                        Click to view code ‚Üí
                    </div>
                </div>
            </div>

            <!-- Method 2: vLLM Deployment -->
            <div class="deployment-card emerald bg-gradient-to-br from-emerald-50 to-green-100 rounded-xl p-6 border border-emerald-200" 
                 onclick="selectDeploymentMethod('vllm')" data-method="vllm">
                <div class="flex items-center mb-4">
                    <span class="text-2xl mr-3">üöÄ</span>
                    <h3 class="text-xl font-bold text-gray-900">vLLM Deployment</h3>
                </div>
                <p class="text-gray-600 mb-4">Optimized for high-throughput and production</p>
                
                <div class="mb-4">
                    <div class="text-sm font-semibold text-green-700 mb-2">‚úÖ Pros:</div>
                    <ul class="text-sm text-gray-600 space-y-1">
                        <li>‚Ä¢ Fast batch processing & inference</li>
                        <li>‚Ä¢ Production-ready scalability</li>
                        <li>‚Ä¢ Optimized memory usage</li>
                    </ul>
                </div>
                
                <div class="mb-4">
                    <div class="text-sm font-semibold text-orange-700 mb-2">‚ö†Ô∏è Cons:</div>
                    <ul class="text-sm text-gray-600 space-y-1">
                        <li>‚Ä¢ Requires vLLM setup and configuration</li>
                        <li>‚Ä¢ More complex deployment</li>
                    </ul>
                </div>

                <div class="mb-4">
                    <div class="text-sm font-semibold text-emerald-700 mb-2">üí° Best for:</div>
                    <ul class="text-sm text-gray-600 space-y-1">
                        <li>‚Ä¢ Production environments</li>
                        <li>‚Ä¢ RLHF training loops</li>
                        <li>‚Ä¢ Large-scale evaluation</li>
                    </ul>
                </div>
                
                <div class="flex justify-center">
                    <div class="text-emerald-600 text-sm font-medium bg-emerald-100 px-3 py-2 rounded-lg hover:bg-emerald-200 transition-colors">
                        Click to view code ‚Üí
                    </div>
                </div>
            </div>

            <!-- Method 3: HuggingFace Integration -->
            <div class="deployment-card purple bg-gradient-to-br from-purple-50 to-violet-100 rounded-xl p-6 border border-purple-200" 
                 onclick="selectDeploymentMethod('huggingface')" data-method="huggingface">
                <div class="flex items-center mb-4">
                    <span class="text-2xl mr-3">üîß</span>
                    <h3 class="text-xl font-bold text-gray-900">HuggingFace Direct</h3>
                </div>
                <p class="text-gray-600 mb-4">Maximum flexibility for custom workflows</p>
                
                <div class="mb-4">
                    <div class="text-sm font-semibold text-green-700 mb-2">‚úÖ Pros:</div>
                    <ul class="text-sm text-gray-600 space-y-1">
                        <li>‚Ä¢ Full control over processing</li>
                        <li>‚Ä¢ Custom integration possibilities</li>
                        <li>‚Ä¢ Access to HuggingFace ecosystem</li>
                    </ul>
                </div>
                
                <div class="mb-4">
                    <div class="text-sm font-semibold text-orange-700 mb-2">‚ö†Ô∏è Cons:</div>
                    <ul class="text-sm text-gray-600 space-y-1">
                        <li>‚Ä¢ Requires manual output parsing</li>
                        <li>‚Ä¢ More setup and boilerplate code</li>
                    </ul>
                </div>

                <div class="mb-4">
                    <div class="text-sm font-semibold text-purple-700 mb-2">üí° Best for:</div>
                    <ul class="text-sm text-gray-600 space-y-1">
                        <li>‚Ä¢ Custom integration workflows</li>
                        <li>‚Ä¢ Advanced model customization</li>
                        <li>‚Ä¢ Research requiring low-level control</li>
                    </ul>
                </div>
                
                <div class="flex justify-center">
                    <div class="text-purple-600 text-sm font-medium bg-purple-100 px-3 py-2 rounded-lg hover:bg-purple-200 transition-colors">
                        Click to view code ‚Üí
                    </div>
                </div>
            </div>
        </div>

        <!-- Code Examples -->
        <div class="bg-gray-50 rounded-xl p-8">
            <!-- Local Inference Tab -->
            <div id="local-tab" class="tab-content">
                <h4 class="text-lg font-bold text-gray-900 mb-4">üè† Local Inference - Recommended for Quick Testing</h4>
                <div class="rounded-lg overflow-hidden">
                    <pre><code class="language-python">import rewardanything

# Load model locally (downloads automatically on first use)
reward_model = rewardanything.RewardModel("zhuohaoyu/RewardAnything-8B-v1")

# Define your evaluation principle
principle = "Judge responses based on helpfulness, accuracy, and clarity. Prefer concise but complete answers."

# Prepare responses to evaluate
prompt = "How do I learn Python programming?"
responses = {
    "assistant_a": "Start with Python.org tutorials, practice daily coding, and build small projects.",
    "assistant_b": "Python is a programming language. It's used for many things.",
    "assistant_c": "Begin with Python.org's official tutorial, practice coding daily, join communities like r/learnpython, and work on projects that interest you."
}

# Evaluate and get results
result = reward_model.judge(
    principle=principle,
    prompt=prompt,
    responses=responses
)

# Access results
print(f"Scores: {result.scores}")
print(f"Ranking: {result.ranking}")
print(f"Explanation: {result.explanation}")</code></pre>
                </div>
            </div>

            <!-- vLLM Deployment Tab -->
            <div id="vllm-tab" class="tab-content hidden">
                <h4 class="text-lg font-bold text-gray-900 mb-4">üöÄ vLLM Deployment - Optimized for Production</h4>
                <div class="space-y-6">
                    <div>
                        <h5 class="font-semibold text-gray-800 mb-2">Step 1: Setup vLLM Server</h5>
                        <div class="rounded-lg overflow-hidden">
                            <pre><code class="language-bash"># Install vLLM
pip install vllm

# Start vLLM server with RewardAnything model
vllm serve zhuohaoyu/RewardAnything-8B-v1 \
    --host 0.0.0.0 \
    --port 8000 \
    --max-model-len 8192 \
    --tensor-parallel-size 1</code></pre>
                        </div>
                    </div>

                    <div>
                        <h5 class="font-semibold text-gray-800 mb-2">Step 2: Start RewardAnything Server</h5>
                        <div class="rounded-lg overflow-hidden">
                            <pre><code class="language-bash"># Start the RewardAnything API server
rewardanything serve -c config.json --port 8001</code></pre>
                        </div>
                    </div>

                    <div>
                        <h5 class="font-semibold text-gray-800 mb-2">Step 3: Use in Your Code</h5>
                        <div class="rounded-lg overflow-hidden">
                            <pre><code class="language-python">import rewardanything

# Connect to the RewardAnything server
client = rewardanything.Client("http://localhost:8001")

# Process batch requests efficiently
requests = [
    {
        "principle": "Prefer clear, concise and helpful responses...",
        "prompt": "How to learn programming?",
        "responses": {
            "assistant_a": "Start with Python, practice daily, build projects.",
            "assistant_b": "Read books and hope for the best.",
            "assistant_c": "Start with Python.org's tutorial, practice daily..."
        }
    },
    # ... more requests
]

results = client.judge_batch(requests)
for result in results:
    print(f"Winner: {result.ranking[0]}")</code></pre>
                        </div>
                    </div>
                </div>
            </div>

            <!-- HuggingFace Direct Tab -->
            <div id="huggingface-tab" class="tab-content hidden">
                <h4 class="text-lg font-bold text-gray-900 mb-4">üîß Direct HuggingFace Integration - Maximum Flexibility</h4>
                <div class="rounded-lg overflow-hidden">
                    <pre><code class="language-python">from transformers import AutoTokenizer, AutoModelForCausalLM
from rewardanything.processing import prepare_chat_messages, parse_rewardanything_output
import torch

# Load model and tokenizer directly
model = AutoModelForCausalLM.from_pretrained(
    "zhuohaoyu/RewardAnything-8B-v1",
    torch_dtype="auto",
    device_map="auto"
)
tokenizer = AutoTokenizer.from_pretrained("zhuohaoyu/RewardAnything-8B-v1")

# Prepare evaluation data
principle = "Judge responses based on helpfulness and accuracy"
prompt = "What is the capital of France?"
responses = {
    "model_a": "Paris is the capital of France.",
    "model_b": "I think it might be Lyon or Paris."
}

# Prepare chat messages (handles masking automatically)
messages, masked2real = prepare_chat_messages(principle, prompt, responses)

# Format with chat template
formatted_input = tokenizer.apply_chat_template(
    messages, tokenize=False, add_generation_prompt=True
)

# Generate response
inputs = tokenizer(formatted_input, return_tensors="pt").to(model.device)
with torch.no_grad():
    outputs = model.generate(
        **inputs,
        max_new_tokens=4096,
        temperature=0.1,
        do_sample=True,
        pad_token_id=tokenizer.eos_token_id
    )

# Parse structured results (handles JSON parsing robustly)
output_text = tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)
result = parse_rewardanything_output(output_text, masked2real)

print(f"Parsed scores: {result.scores}")
print(f"Ranking: {result.ranking}")</code></pre>
                </div>
            </div>
        </div>

        <!-- Decision Matrix (moved below, simplified) -->
        <div class="mt-16 bg-white rounded-xl p-8 shadow-sm border border-gray-200">
            <h3 class="text-xl font-bold text-gray-900 mb-6 text-center">Quick Decision Guide</h3>
            <div class="overflow-x-auto">
                <table class="min-w-full">
                    <thead>
                        <tr class="border-b border-gray-200">
                            <th class="px-6 py-3 text-left text-sm font-medium text-gray-500 uppercase tracking-wider">Use Case</th>
                            <th class="px-6 py-3 text-left text-sm font-medium text-gray-500 uppercase tracking-wider">Recommended Method</th>
                            <th class="px-6 py-3 text-left text-sm font-medium text-gray-500 uppercase tracking-wider">Why</th>
                        </tr>
                    </thead>
                    <tbody class="divide-y divide-gray-200">
                        <tr>
                            <td class="px-6 py-4 whitespace-nowrap text-sm text-gray-900">Quick testing</td>
                            <td class="px-6 py-4 whitespace-nowrap text-sm font-medium text-blue-600">Local Inference</td>
                            <td class="px-6 py-4 text-sm text-gray-600">Simple setup, immediate results</td>
                        </tr>
                        <tr class="bg-gray-50">
                            <td class="px-6 py-4 whitespace-nowrap text-sm text-gray-900">Production evaluation</td>
                            <td class="px-6 py-4 whitespace-nowrap text-sm font-medium text-emerald-600">vLLM Deployment</td>
                            <td class="px-6 py-4 text-sm text-gray-600">Scalable, reliable, optimized</td>
                        </tr>
                        <tr>
                            <td class="px-6 py-4 whitespace-nowrap text-sm text-gray-900">Custom integration</td>
                            <td class="px-6 py-4 whitespace-nowrap text-sm font-medium text-purple-600">Direct HuggingFace</td>
                            <td class="px-6 py-4 text-sm text-gray-600">Maximum flexibility</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>
    </div>
</section>

<!-- Advanced Usage -->
<section class="py-20 bg-gray-50">
    <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
        <div class="text-center mb-16">
            <h2 class="text-3xl md:text-4xl font-bold text-gray-900 mb-4">üî¨ Advanced Usage</h2>
            <p class="text-xl text-gray-600 max-w-4xl mx-auto">
                Unlock the full potential of RewardAnything with sophisticated principles and RLHF integration.
            </p>
        </div>

        <div class="grid md:grid-cols-2 gap-8">
            <!-- Custom Principles -->
            <div class="bg-white rounded-xl p-8 shadow-sm border border-gray-200">
                <h3 class="text-xl font-bold text-gray-900 mb-4">üéØ Custom Principles</h3>
                <p class="text-gray-600 mb-4">RewardAnything excels with sophisticated, multi-criteria principles:</p>
                <div class="rounded-lg overflow-hidden">
                    <pre><code class="language-python">complex_principle = """
Evaluate responses using these criteria:
1. **Technical Accuracy** (40%): Factual correctness
2. **Clarity** (30%): Clear explanations  
3. **Practical Value** (20%): Actionable advice
4. **Safety** (10%): No harmful content

Priority: safety > accuracy > clarity > practical value.
"""

result = reward_model.judge(complex_principle, prompt, responses)</code></pre>
                </div>
            </div>

            <!-- RLHF Integration -->
            <div class="bg-white rounded-xl p-8 shadow-sm border border-gray-200">
                <h3 class="text-xl font-bold text-gray-900 mb-4">üîÑ RLHF Integration</h3>
                <p class="text-gray-600 mb-4">Seamlessly integrate with your RLHF training pipelines:</p>
                <div class="rounded-lg overflow-hidden">
                    <pre><code class="language-python"># Example: Use in PPO training loop
def reward_function(principle, prompt, response):
    result = reward_model.judge(
        principle=principle,
        prompt=prompt,
        responses={"generated": response, "reference": "baseline"}
    )
    return result.scores["generated"]

# Use in your RLHF training
rewards = [reward_function(principle, prompt, resp) 
          for resp in generated_responses]</code></pre>
                </div>
            </div>
        </div>
    </div>
</section>

<!-- Performance Results -->
<section class="py-20 bg-gradient-to-br from-blue-50 to-indigo-100">
    <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
        <div class="text-center mb-16">
            <h2 class="text-3xl md:text-4xl font-bold text-gray-900 mb-4">State-of-the-Art Performance</h2>
            <p class="text-xl text-gray-600 max-w-3xl mx-auto">
                RewardAnything achieves excellent performance on both traditional benchmarks and our new principle-following evaluation
            </p>
        </div>

        <div class="grid grid-cols-1 md:grid-cols-3 gap-8">
            <!-- RM-Bench Results -->
            <div class="bg-white p-8 rounded-xl shadow-sm">
                <div class="text-center mb-6">
                    <div class="text-3xl font-bold text-blue-600 mb-2">89.2%</div>
                    <div class="text-lg font-semibold text-gray-900">RM-Bench Accuracy</div>
                    <div class="text-sm text-gray-600">State-of-the-art on challenging "hard" settings</div>
                </div>
                <div class="space-y-3 text-sm">
                    <div class="flex justify-between">
                        <span class="text-gray-600">Math:</span>
                        <span class="font-semibold">89.1%</span>
                    </div>
                    <div class="flex justify-between">
                        <span class="text-gray-600">Code:</span>
                        <span class="font-semibold">89.1%</span>
                    </div>
                    <div class="flex justify-between">
                        <span class="text-gray-600">Safety:</span>
                        <span class="font-semibold">89.6%</span>
                    </div>
                </div>
            </div>

            <!-- RABench Results -->
            <div class="bg-white p-8 rounded-xl shadow-sm">
                <div class="text-center mb-6">
                    <div class="text-3xl font-bold text-green-600 mb-2">80.5%</div>
                    <div class="text-lg font-semibold text-gray-900">RABench Accuracy</div>
                    <div class="text-sm text-gray-600">Novel benchmark for principle-following</div>
                </div>
                <div class="space-y-3 text-sm">
                    <div class="flex justify-between">
                        <span class="text-gray-600">Content:</span>
                        <span class="font-semibold">82.6%</span>
                    </div>
                    <div class="flex justify-between">
                        <span class="text-gray-600">Logic:</span>
                        <span class="font-semibold">80.7%</span>
                    </div>
                    <div class="flex justify-between">
                        <span class="text-gray-600">Style:</span>
                        <span class="font-semibold">80.5%</span>
                    </div>
                </div>
            </div>

            <!-- Key Advantages -->
            <div class="bg-white p-8 rounded-xl shadow-sm">
                <div class="text-center mb-6">
                    <div class="text-3xl font-bold text-purple-600 mb-2">Zero</div>
                    <div class="text-lg font-semibold text-gray-900">Retraining Required</div>
                    <div class="text-sm text-gray-600">Adapt to new principles instantly</div>
                </div>
                <div class="space-y-3 text-sm">
                    <div class="flex items-center">
                        <div class="w-2 h-2 bg-green-500 rounded-full mr-2"></div>
                        <span>200+ principle categories</span>
                    </div>
                    <div class="flex items-center">
                        <div class="w-2 h-2 bg-green-500 rounded-full mr-2"></div>
                        <span>Listwise evaluation</span>
                    </div>
                    <div class="flex items-center">
                        <div class="w-2 h-2 bg-green-500 rounded-full mr-2"></div>
                        <span>Transparent reasoning</span>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<!-- Key Features -->
<section class="py-20 bg-white">
    <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
        <div class="text-center mb-16">
            <h2 class="text-3xl md:text-4xl font-bold text-gray-900 mb-4">Key Innovations</h2>
            <p class="text-xl text-gray-600 max-w-3xl mx-auto">
                RewardAnything introduces novel techniques for principle-following reward modeling
            </p>
        </div>

        <div class="grid grid-cols-1 md:grid-cols-2 gap-12">
            <div class="space-y-8">
                <div class="space-y-4">
                    <div class="flex items-start">
                        <div class="bg-blue-100 p-2 rounded-lg mr-4">
                            <svg class="w-5 h-5 text-blue-600" fill="currentColor" viewBox="0 0 20 20">
                                <path d="M9 12l2 2 4-4m6 2a9 9 0 11-18 0 9 9 0 0118 0z"/>
                            </svg>
                        </div>
                        <div>
                            <h4 class="font-semibold text-gray-900">Group Relative Policy Optimization (GRPO)</h4>
                            <p class="text-gray-600">Advanced RL training that learns relative preferences within response groups</p>
                        </div>
                    </div>
                    <div class="flex items-start">
                        <div class="bg-blue-100 p-2 rounded-lg mr-4">
                            <svg class="w-5 h-5 text-blue-600" fill="currentColor" viewBox="0 0 20 20">
                                <path d="M9 12l2 2 4-4m6 2a9 9 0 11-18 0 9 9 0 0118 0z"/>
                            </svg>
                        </div>
                        <div>
                            <h4 class="font-semibold text-gray-900">Listwise Evaluation</h4>
                            <p class="text-gray-600">Efficient ranking of multiple responses in a single forward pass</p>
                        </div>
                    </div>
                    <div class="flex items-start">
                        <div class="bg-blue-100 p-2 rounded-lg mr-4">
                            <svg class="w-5 h-5 text-blue-600" fill="currentColor" viewBox="0 0 20 20">
                                <path d="M9 12l2 2 4-4m6 2a9 9 0 11-18 0 9 9 0 0118 0z"/>
                            </svg>
                        </div>
                        <div>
                            <h4 class="font-semibold text-gray-900">Inference-Time Reasoning</h4>
                            <p class="text-gray-600">Explicit reasoning process for transparent decision making</p>
                        </div>
                    </div>
                </div>
                <div class="space-y-4">
                    <div class="flex items-start">
                        <div class="bg-green-100 p-2 rounded-lg mr-4">
                            <svg class="w-5 h-5 text-green-600" fill="currentColor" viewBox="0 0 20 20">
                                <path d="M9 12l2 2 4-4m6 2a9 9 0 11-18 0 9 9 0 0118 0z"/>
                            </svg>
                        </div>
                        <div>
                            <h4 class="font-semibold text-gray-900">Multi-LLM Consensus</h4>
                            <p class="text-gray-600">Ground truth from 4 state-of-the-art LLMs with algorithmic consensus</p>
                        </div>
                    </div>
                    <div class="flex items-start">
                        <div class="bg-green-100 p-2 rounded-lg mr-4">
                            <svg class="w-5 h-5 text-green-600" fill="currentColor" viewBox="0 0 20 20">
                                <path d="M9 12l2 2 4-4m6 2a9 9 0 11-18 0 9 9 0 0118 0z"/>
                            </svg>
                        </div>
                        <div>
                            <h4 class="font-semibold text-gray-900">Human Verification</h4>
                            <p class="text-gray-600">89% agreement rate with Œ∫=0.57 for reliable evaluation standards</p>
                        </div>
                    </div>
                </div>
            </div>

            <!-- RABench Description -->
            <div class="bg-gray-50 p-8 rounded-xl">
                <h3 class="text-xl font-bold text-gray-900 mb-4">RABench: Novel Evaluation Framework</h3>
                <p class="text-gray-700 mb-6">
                    We introduce RABench, a comprehensive benchmark specifically designed to evaluate reward models' 
                    ability to follow explicit natural language principles across diverse domains and criteria.
                </p>
                <div class="space-y-4">
                    <div class="flex items-center">
                        <div class="w-3 h-3 bg-blue-500 rounded-full mr-3"></div>
                        <span class="text-gray-700"><strong>1,002 validated rankings</strong> across 50 principles</span>
                    </div>
                    <div class="flex items-center">
                        <div class="w-3 h-3 bg-green-500 rounded-full mr-3"></div>
                        <span class="text-gray-700"><strong>5 principle categories:</strong> Content, Logic, Style, Tone, Structure</span>
                    </div>
                    <div class="flex items-center">
                        <div class="w-3 h-3 bg-purple-500 rounded-full mr-3"></div>
                        <span class="text-gray-700"><strong>Multiple domains:</strong> Chat, Code, Safety, Math</span>
                    </div>
                    <div class="flex items-center">
                        <div class="w-3 h-3 bg-orange-500 rounded-full mr-3"></div>
                        <span class="text-gray-700"><strong>Human-verified quality</strong> with high inter-annotator agreement</span>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<!-- Documentation -->
<section id="documentation" class="py-20 bg-gray-50">
    <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
        <div class="text-center mb-16">
            <h2 class="text-3xl md:text-4xl font-bold text-gray-900 mb-4">Documentation & Resources</h2>
            <p class="text-xl text-gray-600 max-w-3xl mx-auto">
                Everything you need to understand and use RewardAnything for your research and applications
            </p>
        </div>

        <div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-4 gap-6">
            <a href="{{ site.paper_url | default: '#' }}" class="block bg-blue-50 p-6 rounded-xl hover:bg-blue-100 transition-colors">
                <div class="text-2xl mb-3">üìÑ</div>
                <h3 class="font-semibold text-blue-900 mb-2">Research Paper</h3>
                <p class="text-sm text-blue-700">Complete methodology, experiments, and theoretical foundations</p>
            </a>

            <a href="#" class="block bg-green-50 p-6 rounded-xl hover:bg-green-100 transition-colors">
                <div class="text-2xl mb-3">üöÄ</div>
                <h3 class="font-semibold text-green-900 mb-2">API Documentation</h3>
                <p class="text-sm text-green-700">Comprehensive guide to using RewardAnything in your code</p>
            </a>

            <a href="#" class="block bg-purple-50 p-6 rounded-xl hover:bg-purple-100 transition-colors">
                <div class="text-2xl mb-3">üìä</div>
                <h3 class="font-semibold text-purple-900 mb-2">RABench Dataset</h3>
                <p class="text-sm text-purple-700">Benchmark dataset for evaluating principle-following capabilities</p>
            </a>

            <a href="{{ site.huggingface_url | default: '#' }}" class="block bg-orange-50 p-6 rounded-xl hover:bg-orange-100 transition-colors">
                <div class="text-2xl mb-3">ü§ó</div>
                <h3 class="font-semibold text-orange-900 mb-2">Model Weights</h3>
                <p class="text-sm text-orange-700">Pre-trained models ready for inference and fine-tuning</p>
            </a>
        </div>
    </div>
</section>

<!-- Citation -->
<section class="py-20 bg-gray-900 text-white">
    <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
        <div class="text-center mb-12">
            <h2 class="text-3xl md:text-4xl font-bold mb-4">Citation</h2>
            <p class="text-xl text-gray-300 max-w-3xl mx-auto">
                If you use RewardAnything in your research, please cite our paper
            </p>
        </div>

        <div class="max-w-4xl mx-auto">
            <div class="bg-gray-800 p-6 rounded-xl">
                <pre><code class="language-latex">@article{yu2024rewardanything,
  title={RewardAnything: Generalizable Principle-Following Reward Models},
  author={Yu, Zhuohao and Zeng, Jiali and Gu, Weizheng and Wang, Yidong and 
          Wang, Jindong and Meng, Fandong and Zhou, Jie and Zhang, Yue and 
          Zhang, Shikun and Ye, Wei},
  journal={arXiv preprint arXiv:XXXX.XXXXX},
  year={2025}
}</code></pre>
            </div>
        </div>
    </div>
</section>

<style>
/* Special container for paper figures with neutral background */
.paper-figure-container {
    background: linear-gradient(135deg, #f8fafc 0%, #f1f5f9 100%);
    padding: 2rem;
    border-radius: 1rem;
    border: 1px solid #e2e8f0;
    box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.05);
}

.paper-figure-container img {
    background: white;
    padding: 1rem;
    border-radius: 0.5rem;
    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
}

.tab-button {
    @apply px-4 py-2 rounded-lg text-sm font-medium transition-colors;
    @apply bg-gray-200 text-gray-700 hover:bg-gray-300;
}

.tab-button.active {
    @apply bg-blue-600 text-white hover:bg-blue-700;
}

.tab-content {
    @apply transition-all duration-300;
}
</style> 

<script>
function selectDeploymentMethod(method) {
    // Remove selected state from all cards
    document.querySelectorAll('.deployment-card').forEach(card => {
        card.classList.remove('selected');
    });
    
    // Add selected state to clicked card
    document.querySelector(`[data-method="${method}"]`).classList.add('selected');
    
    // Show corresponding tab
    showTab(method);
}

function showTab(tabName) {
    // Hide all tab contents
    document.querySelectorAll('.tab-content').forEach(tab => {
        tab.classList.add('hidden');
    });
    
    // Show selected tab content
    document.getElementById(tabName + '-tab').classList.remove('hidden');
    
    // Trigger Prism.js to highlight code
    if (typeof Prism !== 'undefined') {
        Prism.highlightAll();
    }
}

// Initialize on page load
document.addEventListener('DOMContentLoaded', function() {
    // Select first deployment method by default WITHOUT scrolling
    document.querySelector(`[data-method="local"]`).classList.add('selected');
    showTab('local');
    
    // Highlight all code blocks
    if (typeof Prism !== 'undefined') {
        Prism.highlightAll();
    }
});
</script> 